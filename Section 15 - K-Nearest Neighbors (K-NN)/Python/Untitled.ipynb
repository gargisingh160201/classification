{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K Nearest Neighbor(KNN)\n",
    "Notice: You should find the best k to build the model with the best accuracy.\n",
    "warning: You should not use the loan_test.csv for finding the best k, however, you can split your train_loan.csv into train and test to find the best k.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)\n",
    "Train set: (276, 8) (276,)\n",
    "Test set: (70, 8) (70,)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "k = 3\n",
    "\n",
    "kNN_model = KNeighborsClassifier(n_neighbors=k).fit(X_train,y_train)\n",
    "kNN_model\n",
    "\n",
    "yhat = kNN_model.predict(X_test)\n",
    "yhat[0:5]\n",
    "array(['PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF'],\n",
    "      dtype=object)\n",
    "# Best k\n",
    "Ks=15\n",
    "mean_acc=np.zeros((Ks-1))\n",
    "std_acc=np.zeros((Ks-1))\n",
    "ConfustionMx=[];\n",
    "for n in range(1,Ks):\n",
    "    \n",
    "    #Train Model and Predict  \n",
    "    KNN = KNeighborsClassifier(n_neighbors=n).fit(X_train,y_train)\n",
    "    yhat = KNN.predict(X_test)\n",
    "    \n",
    "    \n",
    "    mean_acc[n-1]=np.mean(yhat==y_test);\n",
    "    \n",
    "    std_acc[n-1]=np.std(yhat==y_test)/np.sqrt(yhat.shape[0])\n",
    "mean_acc\n",
    "array([0.67142857, 0.65714286, 0.71428571, 0.68571429, 0.75714286,\n",
    "       0.71428571, 0.78571429, 0.75714286, 0.75714286, 0.67142857,\n",
    "       0.7       , 0.72857143, 0.7       , 0.7       ])\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "k = 7\n",
    "#Train Model and Predict  \n",
    "KNN = KNeighborsClassifier(n_neighbors=k).fit(X_train,y_train)\n",
    "KNN\n",
    "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=None, n_neighbors=7, p=2,\n",
    "           weights='uniform')\n",
    "Decision Tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)\n",
    "Train set: (276, 8) (276,)\n",
    "Test set: (70, 8) (70,)\n",
    "DT = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4)\n",
    "DT.fit(X_train,y_train)\n",
    "DT\n",
    "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=4,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best')\n",
    "yhat = DT.predict(X_test)\n",
    "yhat\n",
    "array(['COLLECTION', 'COLLECTION', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF',\n",
    "       'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'COLLECTION',\n",
    "       'PAIDOFF', 'COLLECTION', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF',\n",
    "       'PAIDOFF', 'COLLECTION', 'PAIDOFF', 'COLLECTION', 'PAIDOFF',\n",
    "       'PAIDOFF', 'COLLECTION', 'COLLECTION', 'COLLECTION', 'PAIDOFF',\n",
    "       'COLLECTION', 'COLLECTION', 'PAIDOFF', 'COLLECTION', 'PAIDOFF',\n",
    "       'COLLECTION', 'COLLECTION', 'COLLECTION', 'PAIDOFF', 'PAIDOFF',\n",
    "       'PAIDOFF', 'COLLECTION', 'PAIDOFF', 'COLLECTION', 'PAIDOFF',\n",
    "       'COLLECTION', 'PAIDOFF', 'PAIDOFF', 'COLLECTION', 'PAIDOFF',\n",
    "       'COLLECTION', 'COLLECTION', 'COLLECTION', 'PAIDOFF', 'PAIDOFF',\n",
    "       'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF',\n",
    "       'PAIDOFF', 'PAIDOFF', 'COLLECTION', 'PAIDOFF', 'PAIDOFF',\n",
    "       'PAIDOFF', 'PAIDOFF', 'COLLECTION', 'PAIDOFF', 'COLLECTION',\n",
    "       'PAIDOFF', 'COLLECTION', 'PAIDOFF', 'PAIDOFF'], dtype=object)\n",
    "Support Vector Machine\n",
    "from sklearn import svm\n",
    "SVM = svm.SVC()\n",
    "SVM.fit(X_train, y_train)\n",
    "/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
    "  \"avoid this warning.\", FutureWarning)\n",
    "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
    "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
    "  shrinking=True, tol=0.001, verbose=False)\n",
    "yhat = SVM.predict(X_test)\n",
    "yhat\n",
    "array(['COLLECTION', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF',\n",
    "       'PAIDOFF', 'COLLECTION', 'COLLECTION', 'PAIDOFF', 'PAIDOFF',\n",
    "       'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF',\n",
    "       'COLLECTION', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF',\n",
    "       'PAIDOFF', 'COLLECTION', 'COLLECTION', 'PAIDOFF', 'COLLECTION',\n",
    "       'COLLECTION', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF',\n",
    "       'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF',\n",
    "       'PAIDOFF', 'COLLECTION', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF',\n",
    "       'PAIDOFF', 'COLLECTION', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF',\n",
    "       'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF',\n",
    "       'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF',\n",
    "       'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'COLLECTION',\n",
    "       'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF'],\n",
    "      dtype=object)\n",
    "Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "LR = LogisticRegression(C=0.01).fit(X_train,y_train)\n",
    "LR\n",
    "/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
    "  FutureWarning)\n",
    "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
    "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
    "          tol=0.0001, verbose=0, warm_start=False)\n",
    "yhat = LR.predict(X_test)\n",
    "yhat\n",
    "array(['COLLECTION', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF',\n",
    "       'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF',\n",
    "       'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF',\n",
    "       'COLLECTION', 'PAIDOFF', 'COLLECTION', 'PAIDOFF', 'PAIDOFF',\n",
    "       'PAIDOFF', 'COLLECTION', 'PAIDOFF', 'PAIDOFF', 'COLLECTION',\n",
    "       'COLLECTION', 'PAIDOFF', 'COLLECTION', 'PAIDOFF', 'PAIDOFF',\n",
    "       'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF',\n",
    "       'COLLECTION', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'COLLECTION',\n",
    "       'PAIDOFF', 'PAIDOFF', 'COLLECTION', 'PAIDOFF', 'PAIDOFF',\n",
    "       'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF',\n",
    "       'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF',\n",
    "       'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF',\n",
    "       'COLLECTION', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF',\n",
    "       'PAIDOFF', 'PAIDOFF'], dtype=object)\n",
    "Model Evaluation using Test set\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import log_loss\n",
    "First, download and load the test set:\n",
    "\n",
    "!wget -O loan_test.csv https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/loan_test.csv\n",
    "--2020-08-12 11:03:08--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/loan_test.csv\n",
    "Resolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\n",
    "Connecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\n",
    "HTTP request sent, awaiting response... 200 OK\n",
    "Length: 3642 (3.6K) [text/csv]\n",
    "Saving to: ‘loan_test.csv’\n",
    "\n",
    "100%[======================================>] 3,642       --.-K/s   in 0s      \n",
    "\n",
    "2020-08-12 11:03:08 (267 MB/s) - ‘loan_test.csv’ saved [3642/3642]\n",
    "\n",
    "Load Test set for evaluation\n",
    "test_df = pd.read_csv('loan_test.csv')\n",
    "test_df.head()\n",
    "Unnamed: 0\tUnnamed: 0.1\tloan_status\tPrincipal\tterms\teffective_date\tdue_date\tage\teducation\tGender\n",
    "0\t1\t1\tPAIDOFF\t1000\t30\t9/8/2016\t10/7/2016\t50\tBechalor\tfemale\n",
    "1\t5\t5\tPAIDOFF\t300\t7\t9/9/2016\t9/15/2016\t35\tMaster or Above\tmale\n",
    "2\t21\t21\tPAIDOFF\t1000\t30\t9/10/2016\t10/9/2016\t43\tHigh School or Below\tfemale\n",
    "3\t24\t24\tPAIDOFF\t1000\t30\t9/10/2016\t10/9/2016\t26\tcollege\tmale\n",
    "4\t35\t35\tPAIDOFF\t800\t15\t9/11/2016\t9/25/2016\t29\tBechalor\tmale\n",
    "#Preprocessing\n",
    "\n",
    "# convert date time\n",
    "test_df['due_date'] = pd.to_datetime(test_df['due_date'])\n",
    "test_df['effective_date'] = pd.to_datetime(test_df['effective_date'])\n",
    "test_df['dayofweek'] = test_df['effective_date'].dt.dayofweek\n",
    "# evaulate weekend field\n",
    "test_df['weekend'] = test_df['dayofweek'].apply(lambda x: 1 if (x>3)  else 0)\n",
    "# convert male to 0 and female to 1\n",
    "test_df['Gender'].replace(to_replace=['male','female'], value=[0,1],inplace=True)\n",
    "# work out education level\n",
    "test_feature = test_df[['Principal','terms','age','Gender','weekend']]\n",
    "test_feature = pd.concat([test_feature,pd.get_dummies(test_df['education'])], axis=1)\n",
    "test_feature.drop(['Master or Above'], axis = 1,inplace=True)\n",
    "\n",
    "# normalize the test data\n",
    "test_X = preprocessing.StandardScaler().fit(test_feature).transform(test_feature)\n",
    "test_X[0:5]\n",
    "# and target result\n",
    "test_y = test_df['loan_status'].values\n",
    "test_y[0:5]\n",
    "/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
    "  return self.partial_fit(X, y)\n",
    "/opt/conda/envs/Python36/lib/python3.6/site-packages/ipykernel/__main__.py:17: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
    "array(['PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF'],\n",
    "      dtype=object)\n",
    "Jaccard Index\n",
    "# evaluate KNN\n",
    "knn_yhat = KNN.predict(test_X)\n",
    "jc1 = round(jaccard_similarity_score(test_y, knn_yhat),2)\n",
    "\n",
    "# evaluate Decision Trees\n",
    "dt_yhat = DT.predict(test_X)\n",
    "jc2 = round(jaccard_similarity_score(test_y, dt_yhat),2)\n",
    "\n",
    "#evaluate SVM\n",
    "svm_yhat = SVM.predict(test_X)\n",
    "jc3 = round(jaccard_similarity_score(test_y, svm_yhat),2)\n",
    "\n",
    "# evaluate Logistic Regression\n",
    "lr_yhat = LR.predict(test_X)\n",
    "jc4 = round(jaccard_similarity_score(test_y, lr_yhat),2)\n",
    "\n",
    "list_jc = [jc1, jc2, jc3, jc4]\n",
    "list_jc\n",
    "[0.67, 0.72, 0.8, 0.74]\n",
    "F1 Score\n",
    "# evaluate KNN\n",
    "fs1 = round(f1_score(test_y, knn_yhat, average='weighted'), 2)\n",
    "\n",
    "# evaluate Desision Trees \n",
    "fs2 = round(f1_score(test_y, dt_yhat, average='weighted'), 2)\n",
    "\n",
    "# evaluate SVM\n",
    "fs3 = round(f1_score(test_y, svm_yhat, average='weighted'), 2)\n",
    "\n",
    "# evaluate Logistic Regression\n",
    "fs4 = round(f1_score(test_y, lr_yhat, average='weighted'),2 )\n",
    "\n",
    "list_fs = [fs1, fs2, fs3, fs4]\n",
    "list_fs\n",
    "[0.63, 0.74, 0.76, 0.66]\n",
    "LogLoss\n",
    "from sklearn.metrics import log_loss\n",
    "lr_prob = LR.predict_proba(test_X)\n",
    "LR_yhat_prob = LR.predict_proba(test_X)\n",
    "\n",
    "list_ll = ['NA', 'NA', 'NA', round(log_loss(test_y, LR_yhat_prob), 2)]\n",
    "list_ll\n",
    "['NA', 'NA', 'NA', 0.57]\n",
    "import pandas as pd\n",
    "\n",
    "# fomulate the report format\n",
    "df = pd.DataFrame(list_jc, index=['KNN','Decision Tree','SVM','Logistic Regression'])\n",
    "df.columns = ['Jaccard']\n",
    "df.insert(loc=1, column='F1-score', value=list_fs)\n",
    "df.insert(loc=2, column='LogLoss', value=list_ll)\n",
    "df.columns.name = 'Algorithm'\n",
    "df\n",
    "Algorithm\tJaccard\tF1-score\tLogLoss\n",
    "KNN\t0.67\t0.63\tNA\n",
    "Decision Tree\t0.72\t0.74\tNA\n",
    "SVM\t0.80\t0.76\tNA\n",
    "Logistic Regression\t0.74\t0.66\t0.57"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
